{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "import torch\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n",
    "from api import StableTTSAPI\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "tts_model_path = 'StableTTS-sfm-vctk.pt' # path to StableTTS checkpoint\n",
    "\n",
    "vocoder_model_path = 'vocoders/pretrained/vocos.pt'\n",
    "vocoder_type = 'vocos'\n",
    "\n",
    "model = StableTTSAPI(tts_model_path, vocoder_model_path, vocoder_type)\n",
    "model.to(device)\n",
    "\n",
    "tts_param, vocoder_param = model.get_params()\n",
    "print(f'tts_param: {tts_param}, vocoder_param: {vocoder_param}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = 'english'\n",
    "solver = 'dopri5' # recommend using euler, midpoint or dopri5\n",
    "steps = 30 # the size of output trajectory, meaningless for the steps of adaptive-step solvers\n",
    "cfg = 3 # recommend 1-4\n",
    "temperature = 1.0\n",
    "alpha = 3.0\n",
    "length_scale = 1.0\n",
    "\n",
    "# folder = \"xxx\"\n",
    "# import os\n",
    "# if os.path.exists(folder):\n",
    "#     os.system(f\"rm -r {folder}\")\n",
    "# os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "with open(\"./data/VCTK/vctk_audio_sid_text_test_filelist.txt\", \"r\") as f:\n",
    "    test_data = f.readlines()\n",
    "\n",
    "SEED = 1234\n",
    "import random\n",
    "random.seed(SEED)\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "tps = 0. \n",
    "sigma_ps = 0.\n",
    "for d in tqdm(test_data):\n",
    "    filename = d.split(\"|\")[0].split(\"/\")[-1]\n",
    "    text = d.split(\"|\")[-1].strip(\"\\n\")\n",
    "    spk = int(d.split(\"|\")[1])\n",
    "    audio_output, outputs, tp, sigma_p = model.inference(text, spk, language, steps, temperature, alpha, length_scale, solver, cfg)\n",
    "    break\n",
    "    # tps += tp \n",
    "    # sigma_ps += sigma_p\n",
    "    # sf.write(f'{folder}/{filename}', audio_output[0], model.mel_config.sample_rate, 'PCM_24')\n",
    "\n",
    "# tps = round(tps/len(test_data), 8)\n",
    "# sigma_ps = round(sigma_ps/len(test_data), 8)\n",
    "# print(tps, sigma_ps)\n",
    "\n",
    "ipd.display(ipd.Audio(audio_output[0], rate=model.mel_config.sample_rate))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "git",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
